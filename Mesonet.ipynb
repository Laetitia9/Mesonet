{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1pmxRb6vg1ORGhswYO6hdS3-278m-0uYr",
      "authorship_tag": "ABX9TyNbqiqtM83upTqv13+5+FZs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laetitia9/Mesonet/blob/main/Mesonet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository belonging to the original author\n",
        "!git clone https://github.com/Laetitia9/Mesonet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ23HbVUX-6a",
        "outputId": "70befd5b-b24e-4608-dc9f-0cd80a826b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mesonet'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwzszWUgxJ7c",
        "outputId": "2d2524b3-f07d-43f8-b952-80bbc6ce03c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (11.0.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=255c0df8a2d99ded4de590284796a75826ac5e10364d188f507875119a0d7961\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from scipy.ndimage import zoom\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "KM8WBVjJwkZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Data Preprocessing\n",
        "# Extract frames from the videos and preprocess them.\n",
        "# This involves face detection, alignment, and resizing.\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_interval=5):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval_frames = int(fps * frame_interval)\n",
        "    frame_count = 0\n",
        "    extracted_frames = 0\n",
        "    success, frame = cap.read()\n",
        "    while success and extracted_frames < 8:\n",
        "        if frame_count % frame_interval_frames == 0:\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            face_locations = face_recognition.face_locations(frame_rgb)\n",
        "            for (top, right, bottom, left) in face_locations:\n",
        "                face_image = frame_rgb[top:bottom, left:right]\n",
        "                face_image = cv2.resize(face_image, (256, 256))\n",
        "                output_path = os.path.join(output_folder, f'{os.path.basename(video_path)}_frame_{extracted_frames}.jpg')\n",
        "                cv2.imwrite(output_path, cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR))\n",
        "                extracted_frames += 1\n",
        "        frame_count += 1\n",
        "        success, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "def preprocess_videos(video_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    for video_file in tqdm(os.listdir(video_folder)):\n",
        "        if video_file.endswith('.mp4'):\n",
        "            video_path = os.path.join(video_folder, video_file)\n",
        "            extract_frames(video_path, output_folder)\n",
        "\n",
        "# Example usage\n",
        "video_folder = '/content/drive/MyDrive/DeepFake Detection Dataset/DFD_manipulated_sequences'\n",
        "output_folder = '/content/drive/MyDrive/DFDD_ Extracted frames/df_frames'\n",
        "preprocess_videos(video_folder, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-27N5mbxZCC",
        "outputId": "bb0f8908-7c97-4acd-dd76-03b3eb78abb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [58:59<00:00, 11.80s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Data Preprocessing\n",
        "# Extract frames from the videos and preprocess them.\n",
        "# This involves face detection, alignment, and resizing.\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_interval=5):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval_frames = int(fps * frame_interval)\n",
        "    frame_count = 0\n",
        "    extracted_frames = 0\n",
        "    success, frame = cap.read()\n",
        "    while success and extracted_frames < 8:\n",
        "        if frame_count % frame_interval_frames == 0:\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            face_locations = face_recognition.face_locations(frame_rgb)\n",
        "            for (top, right, bottom, left) in face_locations:\n",
        "                face_image = frame_rgb[top:bottom, left:right]\n",
        "                face_image = cv2.resize(face_image, (256, 256))\n",
        "                output_path = os.path.join(output_folder, f'{os.path.basename(video_path)}_frame_{extracted_frames}.jpg')\n",
        "                cv2.imwrite(output_path, cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR))\n",
        "                extracted_frames += 1\n",
        "        frame_count += 1\n",
        "        success, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "def preprocess_videos(video_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    for video_file in tqdm(os.listdir(video_folder)):\n",
        "        if video_file.endswith('.mp4'):\n",
        "            video_path = os.path.join(video_folder, video_file)\n",
        "            extract_frames(video_path, output_folder)\n",
        "\n",
        "# Example usage\n",
        "video_folder = '/content/drive/MyDrive/DeepFake Detection Dataset/DFD_original sequences'\n",
        "output_folder = '/content/drive/MyDrive/DFDD_ Extracted frames/r_frames'\n",
        "preprocess_videos(video_folder, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJBTfucVyLVp",
        "outputId": "f27df1ec-c473-4d08-a11a-dea3584e9848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [1:09:47<00:00, 13.96s/it]\n"
          ]
        }
      ]
    }
  ]
}